{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5YODvlrtPFUT"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMr04PJT1RGz8BVuriZ7lqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pvtien96/CORING/blob/main/notebooks/Similarity_based_Filter_Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 1: Introduction**"
      ],
      "metadata": {
        "id": "lVeZS2NhLJ3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook serves as a starter kit to help individuals quickly get started with the project on [similarity-based filter pruning](https://hal.science/hal-04475150v1/file/gretsi2023.pdf). The project focuses on applying filter pruning techniques to the VGG-16-BN architecture trained on the CIFAR-10 dataset using PyTorch. A more comprehensive resource can be found [here](https://github.com/pvtien96/CORING).\n",
        "\n",
        "## Purpose:\n",
        "Filter pruning is an essential technique for reducing the computational complexity and memory footprint of deep neural networks while maintaining or even improving their performance. This notebook provides a step-by-step guide to implementing similarity-based filter pruning, where filters are pruned based on their similarity to others in the network.\n",
        "\n",
        "## Key Components:\n",
        "1. **Setup**: Installs the necessary environment and defines helper functions. *You don't need to worry about these details initially*.\n",
        "\n",
        "2. **Training**: Trains the baseline model on the CIFAR-10 dataset and validates its accuracy.\n",
        "\n",
        "4. **Pruning**: Applies similarity-based filter pruning techniques to the trained model, reducing its size while preserving effectiveness. **This is your main task**.\n",
        "\n",
        "5. **Fine-tuning**: Fine-tunes the pruned model to assess its performance in terms of accuracy and efficiency compared to the original model.\n",
        "\n",
        "6. **Analysis & Conclusion**: Analyze the results, highlights insights gained from the experiment, and provides suggestions for further exploration or improvement.\n",
        "\n",
        "## Prerequisite Skills:\n",
        "- [Basic computer science](https://pll.harvard.edu/course/cs50-introduction-computer-science)\n",
        "- [Deep learning fundamentals](https://cs230.stanford.edu/)\n",
        "- [PyTorch basics and CNNs](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
        "- [Filter pruning techniques](https://arxiv.org/pdf/2308.06767.pdf)\n",
        "\n",
        "Let's dive in and explore the exciting world of filter pruning and deep learning efficiency optimization!\n"
      ],
      "metadata": {
        "id": "2vrswGamLOg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 2: Setup**"
      ],
      "metadata": {
        "id": "5YODvlrtPFUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment"
      ],
      "metadata": {
        "id": "y3TyDMJCPLN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_9R7-eAPUUy",
        "outputId": "703979fb-3026-4eea-e8d3-e59d6ee546ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define VGG-16-BN model"
      ],
      "metadata": {
        "id": "bvA-fbFDPq9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "defaultcfg = [\n",
        "    64,\n",
        "    64,\n",
        "    \"M\",\n",
        "    128,\n",
        "    128,\n",
        "    \"M\",\n",
        "    256,\n",
        "    256,\n",
        "    256,\n",
        "    \"M\",\n",
        "    512,\n",
        "    512,\n",
        "    512,\n",
        "    \"M\",\n",
        "    512,\n",
        "    512,\n",
        "    512,\n",
        "]\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, compress_rate=[0.0] * 13, cfg=None, num_classes=10):\n",
        "        super(VGG, self).__init__()\n",
        "\n",
        "        if cfg is None:\n",
        "            cfg = defaultcfg\n",
        "\n",
        "        self.compress_rate = compress_rate[:]\n",
        "\n",
        "        self.features = self._make_layers(cfg)\n",
        "        last_conv_out_channels = self.features[-3].out_channels\n",
        "        self.classifier = nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\"linear1\", nn.Linear(last_conv_out_channels, cfg[-1])),\n",
        "                    (\"norm1\", nn.BatchNorm1d(cfg[-1])),\n",
        "                    (\"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\"linear2\", nn.Linear(cfg[-1], num_classes)),\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = nn.Sequential()\n",
        "        in_channels = 3\n",
        "        cnt = 0\n",
        "\n",
        "        for i, x in enumerate(cfg):\n",
        "            if x == \"M\":\n",
        "                layers.add_module(\"pool%d\" % i, nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            else:\n",
        "                x = int(x * (1 - self.compress_rate[cnt]))\n",
        "                cnt += 1\n",
        "                conv2d = nn.Conv2d(in_channels, x, kernel_size=3, padding=1)\n",
        "                layers.add_module(\"conv%d\" % i, conv2d)\n",
        "                layers.add_module(\"norm%d\" % i, nn.BatchNorm2d(x))\n",
        "                layers.add_module(\"relu%d\" % i, nn.ReLU(inplace=True))\n",
        "                in_channels = x\n",
        "\n",
        "        return layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = nn.AvgPool2d(2)(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def vgg_16_bn(compress_rate=[0.0] * 13):\n",
        "    return VGG(compress_rate=compress_rate)"
      ],
      "metadata": {
        "id": "PL0WKYG_PYg7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions"
      ],
      "metadata": {
        "id": "BsmPZQRgQb2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_cpr(compress_rate):\n",
        "    cprate_str = compress_rate\n",
        "    cprate_str_list = cprate_str.split(\"+\")\n",
        "    pat_cprate = re.compile(r\"\\d+\\.\\d*\")\n",
        "    pat_num = re.compile(r\"\\*\\d+\")\n",
        "    cprate = []\n",
        "    for x in cprate_str_list:\n",
        "        num = 1\n",
        "        find_num = re.findall(pat_num, x)\n",
        "        if find_num:\n",
        "            assert len(find_num) == 1\n",
        "            num = int(find_num[0].replace(\"*\", \"\"))\n",
        "        find_cprate = re.findall(pat_cprate, x)\n",
        "        assert len(find_cprate) == 1\n",
        "        cprate += [float(find_cprate[0])] * num\n",
        "\n",
        "    return cprate"
      ],
      "metadata": {
        "id": "stzE4MnmQE1b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import time, datetime\n",
        "import logging\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils\n",
        "\n",
        "\n",
        "'''record configurations'''\n",
        "class record_config():\n",
        "    def __init__(self, args):\n",
        "        now = datetime.datetime.now().strftime('%Y-%m-%d-%H:%M:%S')\n",
        "        today = datetime.date.today()\n",
        "\n",
        "        self.args = args\n",
        "        self.job_dir = Path(args.job_dir)\n",
        "\n",
        "        def _make_dir(path):\n",
        "            if not os.path.exists(path):\n",
        "                os.makedirs(path)\n",
        "\n",
        "        _make_dir(self.job_dir)\n",
        "\n",
        "        config_dir = self.job_dir / 'config.txt'\n",
        "        #if not os.path.exists(config_dir):\n",
        "        if args.resume:\n",
        "            with open(config_dir, 'a') as f:\n",
        "                f.write(now + '\\n\\n')\n",
        "                for arg in vars(args):\n",
        "                    f.write('{}: {}\\n'.format(arg, getattr(args, arg)))\n",
        "                f.write('\\n')\n",
        "        else:\n",
        "            with open(config_dir, 'w') as f:\n",
        "                f.write(now + '\\n\\n')\n",
        "                for arg in vars(args):\n",
        "                    f.write('{}: {}\\n'.format(arg, getattr(args, arg)))\n",
        "                f.write('\\n')\n",
        "\n",
        "\n",
        "def get_logger(file_path):\n",
        "\n",
        "    logger = logging.getLogger('gal')\n",
        "    log_format = '%(asctime)s | %(message)s'\n",
        "    formatter = logging.Formatter(log_format, datefmt='%m/%d %I:%M:%S %p')\n",
        "    file_handler = logging.FileHandler(file_path)\n",
        "    file_handler.setFormatter(formatter)\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    stream_handler.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(stream_handler)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    return logger\n",
        "\n",
        "#label smooth\n",
        "class CrossEntropyLabelSmooth(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes, epsilon):\n",
        "    super(CrossEntropyLabelSmooth, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.epsilon = epsilon\n",
        "    self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, inputs, targets):\n",
        "    log_probs = self.logsoftmax(inputs)\n",
        "    targets = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n",
        "    targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
        "    loss = (-targets * log_probs).mean(0).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print(' '.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, save):\n",
        "    if not os.path.exists(save):\n",
        "        os.makedirs(save)\n",
        "    filename = os.path.join(save, 'checkpoint.pth.tar')\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        best_filename = os.path.join(save, 'model_best.pth.tar')\n",
        "        shutil.copyfile(filename, best_filename)\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = args.lr * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "\n",
        "\n",
        "def progress_bar(current, total, msg=None):\n",
        "    _, term_width = os.popen('stty size', 'r').read().split()\n",
        "    term_width = int(term_width)\n",
        "\n",
        "    TOTAL_BAR_LENGTH = 65.\n",
        "    last_time = time.time()\n",
        "    begin_time = last_time\n",
        "\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ],
      "metadata": {
        "id": "7MuvmxS1Sa-r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, train_loader, model, criterion, optimizer, scheduler):\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    cur_lr = optimizer.param_groups[0]['lr']\n",
        "    print('learning_rate: ' + str(cur_lr))\n",
        "\n",
        "    num_iter = len(train_loader)\n",
        "    print_freq = num_iter // 10\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        images = images.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(logits, target, topk=(1, 5))\n",
        "        n = images.size(0)\n",
        "        losses.update(loss.item(), n)  # accumulated loss\n",
        "        top1.update(prec1.item(), n)\n",
        "        top5.update(prec5.item(), n)\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print(\n",
        "                'Epoch[{0}]({1}/{2}): '\n",
        "                'Loss {loss.avg:.4f} '\n",
        "                'Prec@1(1,5) {top1.avg:.2f}, {top5.avg:.2f} '\n",
        "                'Lr {cur_lr:.4f}'.format(\n",
        "                    epoch, i, num_iter, loss=losses,\n",
        "                    top1=top1, top5=top5, cur_lr=cur_lr))\n",
        "    scheduler.step()\n",
        "\n",
        "    return losses.avg, top1.avg, top5.avg\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            images = images.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            # compute output\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            pred1, pred5 = accuracy(logits, target, topk=(1, 5))\n",
        "            n = images.size(0)\n",
        "            losses.update(loss.item(), n)\n",
        "            top1.update(pred1[0], n)\n",
        "            top5.update(pred5[0], n)\n",
        "\n",
        "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
        "                    .format(top1=top1, top5=top5))\n",
        "\n",
        "    return losses.avg, top1.avg, top5.avg"
      ],
      "metadata": {
        "id": "QpORMFk9SFsC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def load_data(batch_size=128):\n",
        "\n",
        "    # load training data\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    trainset = torchvision.datasets.CIFAR10(root=\"./\", train=True, download=True,\n",
        "                                            transform=transform_train)\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    testset = torchvision.datasets.CIFAR10(root=\"./\", train=False, download=True, transform=transform_test)\n",
        "    val_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "wOEgSgHfRYBb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "epochs = 100\n",
        "lr_warmup_epochs=5\n",
        "lr=0.01\n",
        "momentum=0.9\n",
        "weight_decay=5e-4\n",
        "lr_warmup_decay=0.01"
      ],
      "metadata": {
        "id": "85hVYLlKVtUb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune(model, train_loader, val_loader, epochs, criterion):\n",
        "    optimizer = torch.optim.SGD(model.parameters(\n",
        "    ), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    main_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=epochs-lr_warmup_epochs)\n",
        "    warmup_lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "        optimizer, start_factor=lr_warmup_decay, total_iters=lr_warmup_epochs)\n",
        "    scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
        "        optimizer, schedulers=[warmup_lr_scheduler, main_lr_scheduler], milestones=[lr_warmup_epochs])\n",
        "\n",
        "    _, best_top1_acc, _ = validate(val_loader, model, criterion)\n",
        "    best_model_state = copy.deepcopy(model.state_dict())\n",
        "    epoch = 0\n",
        "    while epoch < epochs:\n",
        "        train(epoch, train_loader, model, criterion,\n",
        "              optimizer, scheduler)\n",
        "        _, valid_top1_acc, _ = validate(val_loader, model, criterion)\n",
        "\n",
        "        if valid_top1_acc > best_top1_acc:\n",
        "            best_top1_acc = valid_top1_acc\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "        epoch += 1\n",
        "        print('=>Best accuracy {:.3f}'.format(best_top1_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "tqqne4ZjX5ab"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 3: Train the baseline model**"
      ],
      "metadata": {
        "id": "L9DHHosHQ0KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import copy\n",
        "\n",
        "\n",
        " # initialize model\n",
        "model_ori = vgg_16_bn(compress_rate=[0.0]*13).cuda()\n",
        "print(model_ori)\n",
        "\n",
        "# load training data\n",
        "train_loader, val_loader = load_data()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# train the baseline model\n",
        "epochs = 20 # higher epochs may yield better accuracy.\n",
        "print(\"Start training baseline model:\")\n",
        "model_ori = finetune(model_ori, train_loader, val_loader, epochs, criterion)\n",
        "\n"
      ],
      "metadata": {
        "id": "R7LQVpYnQzYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3555227-71a4-41c8-ddd9-690bfad16ad3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu3): ReLU(inplace=True)\n",
            "    (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu4): ReLU(inplace=True)\n",
            "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu6): ReLU(inplace=True)\n",
            "    (conv7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu7): ReLU(inplace=True)\n",
            "    (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu8): ReLU(inplace=True)\n",
            "    (pool9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu10): ReLU(inplace=True)\n",
            "    (conv11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu11): ReLU(inplace=True)\n",
            "    (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu12): ReLU(inplace=True)\n",
            "    (pool13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu14): ReLU(inplace=True)\n",
            "    (conv15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu15): ReLU(inplace=True)\n",
            "    (conv16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu16): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (linear2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Start training baseline model:\n",
            " * Acc@1 10.000 Acc@5 50.000\n",
            "learning_rate: 0.0001\n",
            "Epoch[0](0/391): Loss 2.3305 Prec@1(1,5) 9.38, 56.25 Lr 0.0001\n",
            "Epoch[0](39/391): Loss 2.2734 Prec@1(1,5) 14.24, 59.61 Lr 0.0001\n",
            "Epoch[0](78/391): Loss 2.1903 Prec@1(1,5) 19.54, 66.43 Lr 0.0001\n",
            "Epoch[0](117/391): Loss 2.1247 Prec@1(1,5) 22.62, 70.58 Lr 0.0001\n",
            "Epoch[0](156/391): Loss 2.0690 Prec@1(1,5) 24.95, 73.63 Lr 0.0001\n",
            "Epoch[0](195/391): Loss 2.0226 Prec@1(1,5) 26.55, 75.86 Lr 0.0001\n",
            "Epoch[0](234/391): Loss 1.9819 Prec@1(1,5) 28.10, 77.67 Lr 0.0001\n",
            "Epoch[0](273/391): Loss 1.9437 Prec@1(1,5) 29.62, 79.09 Lr 0.0001\n",
            "Epoch[0](312/391): Loss 1.9105 Prec@1(1,5) 30.82, 80.26 Lr 0.0001\n",
            "Epoch[0](351/391): Loss 1.8786 Prec@1(1,5) 31.97, 81.23 Lr 0.0001\n",
            "Epoch[0](390/391): Loss 1.8515 Prec@1(1,5) 32.87, 82.09 Lr 0.0001\n",
            " * Acc@1 44.770 Acc@5 91.600\n",
            "=>Best accuracy 44.770\n",
            "learning_rate: 0.00208\n",
            "Epoch[1](0/391): Loss 1.6279 Prec@1(1,5) 41.41, 87.50 Lr 0.0021\n",
            "Epoch[1](39/391): Loss 1.6335 Prec@1(1,5) 39.36, 89.08 Lr 0.0021\n",
            "Epoch[1](78/391): Loss 1.5693 Prec@1(1,5) 42.13, 90.21 Lr 0.0021\n",
            "Epoch[1](117/391): Loss 1.5210 Prec@1(1,5) 44.09, 90.90 Lr 0.0021\n",
            "Epoch[1](156/391): Loss 1.4706 Prec@1(1,5) 46.06, 91.58 Lr 0.0021\n",
            "Epoch[1](195/391): Loss 1.4288 Prec@1(1,5) 47.82, 92.16 Lr 0.0021\n",
            "Epoch[1](234/391): Loss 1.3928 Prec@1(1,5) 49.10, 92.62 Lr 0.0021\n",
            "Epoch[1](273/391): Loss 1.3603 Prec@1(1,5) 50.25, 93.01 Lr 0.0021\n",
            "Epoch[1](312/391): Loss 1.3276 Prec@1(1,5) 51.51, 93.39 Lr 0.0021\n",
            "Epoch[1](351/391): Loss 1.3015 Prec@1(1,5) 52.49, 93.66 Lr 0.0021\n",
            "Epoch[1](390/391): Loss 1.2775 Prec@1(1,5) 53.49, 93.92 Lr 0.0021\n",
            " * Acc@1 62.990 Acc@5 97.100\n",
            "=>Best accuracy 62.990\n",
            "learning_rate: 0.004059999999999999\n",
            "Epoch[2](0/391): Loss 1.0514 Prec@1(1,5) 59.38, 96.09 Lr 0.0041\n",
            "Epoch[2](39/391): Loss 1.0894 Prec@1(1,5) 60.70, 96.29 Lr 0.0041\n",
            "Epoch[2](78/391): Loss 1.0814 Prec@1(1,5) 60.83, 96.50 Lr 0.0041\n",
            "Epoch[2](117/391): Loss 1.0663 Prec@1(1,5) 61.53, 96.44 Lr 0.0041\n",
            "Epoch[2](156/391): Loss 1.0394 Prec@1(1,5) 62.69, 96.58 Lr 0.0041\n",
            "Epoch[2](195/391): Loss 1.0202 Prec@1(1,5) 63.54, 96.72 Lr 0.0041\n",
            "Epoch[2](234/391): Loss 0.9986 Prec@1(1,5) 64.38, 96.82 Lr 0.0041\n",
            "Epoch[2](273/391): Loss 0.9842 Prec@1(1,5) 64.99, 96.90 Lr 0.0041\n",
            "Epoch[2](312/391): Loss 0.9673 Prec@1(1,5) 65.68, 97.00 Lr 0.0041\n",
            "Epoch[2](351/391): Loss 0.9548 Prec@1(1,5) 66.23, 97.08 Lr 0.0041\n",
            "Epoch[2](390/391): Loss 0.9394 Prec@1(1,5) 66.79, 97.16 Lr 0.0041\n",
            " * Acc@1 71.020 Acc@5 97.970\n",
            "=>Best accuracy 71.020\n",
            "learning_rate: 0.0060399999999999985\n",
            "Epoch[3](0/391): Loss 0.7411 Prec@1(1,5) 77.34, 98.44 Lr 0.0060\n",
            "Epoch[3](39/391): Loss 0.8492 Prec@1(1,5) 69.94, 97.93 Lr 0.0060\n",
            "Epoch[3](78/391): Loss 0.8417 Prec@1(1,5) 70.57, 97.80 Lr 0.0060\n",
            "Epoch[3](117/391): Loss 0.8189 Prec@1(1,5) 71.20, 97.85 Lr 0.0060\n",
            "Epoch[3](156/391): Loss 0.8157 Prec@1(1,5) 71.54, 97.85 Lr 0.0060\n",
            "Epoch[3](195/391): Loss 0.8055 Prec@1(1,5) 71.88, 97.88 Lr 0.0060\n",
            "Epoch[3](234/391): Loss 0.7953 Prec@1(1,5) 72.21, 97.97 Lr 0.0060\n",
            "Epoch[3](273/391): Loss 0.7864 Prec@1(1,5) 72.61, 97.98 Lr 0.0060\n",
            "Epoch[3](312/391): Loss 0.7753 Prec@1(1,5) 73.05, 98.08 Lr 0.0060\n",
            "Epoch[3](351/391): Loss 0.7679 Prec@1(1,5) 73.31, 98.09 Lr 0.0060\n",
            "Epoch[3](390/391): Loss 0.7615 Prec@1(1,5) 73.48, 98.11 Lr 0.0060\n",
            " * Acc@1 76.190 Acc@5 98.700\n",
            "=>Best accuracy 76.190\n",
            "learning_rate: 0.008019999999999998\n",
            "Epoch[4](0/391): Loss 0.5910 Prec@1(1,5) 76.56, 100.00 Lr 0.0080\n",
            "Epoch[4](39/391): Loss 0.6810 Prec@1(1,5) 76.39, 98.77 Lr 0.0080\n",
            "Epoch[4](78/391): Loss 0.7023 Prec@1(1,5) 75.65, 98.66 Lr 0.0080\n",
            "Epoch[4](117/391): Loss 0.6972 Prec@1(1,5) 75.77, 98.56 Lr 0.0080\n",
            "Epoch[4](156/391): Loss 0.6850 Prec@1(1,5) 76.14, 98.60 Lr 0.0080\n",
            "Epoch[4](195/391): Loss 0.6825 Prec@1(1,5) 76.17, 98.50 Lr 0.0080\n",
            "Epoch[4](234/391): Loss 0.6717 Prec@1(1,5) 76.62, 98.54 Lr 0.0080\n",
            "Epoch[4](273/391): Loss 0.6718 Prec@1(1,5) 76.67, 98.58 Lr 0.0080\n",
            "Epoch[4](312/391): Loss 0.6673 Prec@1(1,5) 76.89, 98.58 Lr 0.0080\n",
            "Epoch[4](351/391): Loss 0.6636 Prec@1(1,5) 76.97, 98.61 Lr 0.0080\n",
            "Epoch[4](390/391): Loss 0.6601 Prec@1(1,5) 77.08, 98.63 Lr 0.0080\n",
            " * Acc@1 74.430 Acc@5 97.910\n",
            "=>Best accuracy 76.190\n",
            "learning_rate: 0.01\n",
            "Epoch[5](0/391): Loss 0.6063 Prec@1(1,5) 80.47, 99.22 Lr 0.0100\n",
            "Epoch[5](39/391): Loss 0.6021 Prec@1(1,5) 79.41, 98.73 Lr 0.0100\n",
            "Epoch[5](78/391): Loss 0.6271 Prec@1(1,5) 78.30, 98.76 Lr 0.0100\n",
            "Epoch[5](117/391): Loss 0.6306 Prec@1(1,5) 78.28, 98.73 Lr 0.0100\n",
            "Epoch[5](156/391): Loss 0.6277 Prec@1(1,5) 78.34, 98.69 Lr 0.0100\n",
            "Epoch[5](195/391): Loss 0.6328 Prec@1(1,5) 78.12, 98.70 Lr 0.0100\n",
            "Epoch[5](234/391): Loss 0.6272 Prec@1(1,5) 78.32, 98.72 Lr 0.0100\n",
            "Epoch[5](273/391): Loss 0.6211 Prec@1(1,5) 78.64, 98.73 Lr 0.0100\n",
            "Epoch[5](312/391): Loss 0.6188 Prec@1(1,5) 78.67, 98.74 Lr 0.0100\n",
            "Epoch[5](351/391): Loss 0.6134 Prec@1(1,5) 78.89, 98.75 Lr 0.0100\n",
            "Epoch[5](390/391): Loss 0.6051 Prec@1(1,5) 79.21, 98.78 Lr 0.0100\n",
            " * Acc@1 81.240 Acc@5 99.090\n",
            "=>Best accuracy 81.240\n",
            "learning_rate: 0.009890738003669028\n",
            "Epoch[6](0/391): Loss 0.5099 Prec@1(1,5) 80.47, 97.66 Lr 0.0099\n",
            "Epoch[6](39/391): Loss 0.5550 Prec@1(1,5) 80.70, 98.81 Lr 0.0099\n",
            "Epoch[6](78/391): Loss 0.5527 Prec@1(1,5) 80.61, 98.93 Lr 0.0099\n",
            "Epoch[6](117/391): Loss 0.5407 Prec@1(1,5) 81.04, 98.95 Lr 0.0099\n",
            "Epoch[6](156/391): Loss 0.5373 Prec@1(1,5) 81.20, 99.01 Lr 0.0099\n",
            "Epoch[6](195/391): Loss 0.5297 Prec@1(1,5) 81.54, 99.04 Lr 0.0099\n",
            "Epoch[6](234/391): Loss 0.5304 Prec@1(1,5) 81.56, 99.06 Lr 0.0099\n",
            "Epoch[6](273/391): Loss 0.5265 Prec@1(1,5) 81.76, 99.06 Lr 0.0099\n",
            "Epoch[6](312/391): Loss 0.5212 Prec@1(1,5) 81.98, 99.09 Lr 0.0099\n",
            "Epoch[6](351/391): Loss 0.5184 Prec@1(1,5) 82.07, 99.08 Lr 0.0099\n",
            "Epoch[6](390/391): Loss 0.5205 Prec@1(1,5) 81.98, 99.07 Lr 0.0099\n",
            " * Acc@1 81.850 Acc@5 98.990\n",
            "=>Best accuracy 81.850\n",
            "learning_rate: 0.009567727288213004\n",
            "Epoch[7](0/391): Loss 0.4277 Prec@1(1,5) 83.59, 99.22 Lr 0.0096\n",
            "Epoch[7](39/391): Loss 0.4764 Prec@1(1,5) 83.16, 99.32 Lr 0.0096\n",
            "Epoch[7](78/391): Loss 0.4685 Prec@1(1,5) 83.65, 99.30 Lr 0.0096\n",
            "Epoch[7](117/391): Loss 0.4671 Prec@1(1,5) 83.89, 99.27 Lr 0.0096\n",
            "Epoch[7](156/391): Loss 0.4698 Prec@1(1,5) 83.91, 99.28 Lr 0.0096\n",
            "Epoch[7](195/391): Loss 0.4648 Prec@1(1,5) 84.12, 99.29 Lr 0.0096\n",
            "Epoch[7](234/391): Loss 0.4604 Prec@1(1,5) 84.25, 99.30 Lr 0.0096\n",
            "Epoch[7](273/391): Loss 0.4601 Prec@1(1,5) 84.21, 99.30 Lr 0.0096\n",
            "Epoch[7](312/391): Loss 0.4583 Prec@1(1,5) 84.25, 99.32 Lr 0.0096\n",
            "Epoch[7](351/391): Loss 0.4585 Prec@1(1,5) 84.23, 99.31 Lr 0.0096\n",
            "Epoch[7](390/391): Loss 0.4594 Prec@1(1,5) 84.22, 99.29 Lr 0.0096\n",
            " * Acc@1 82.600 Acc@5 98.720\n",
            "=>Best accuracy 82.600\n",
            "learning_rate: 0.009045084971874737\n",
            "Epoch[8](0/391): Loss 0.4024 Prec@1(1,5) 84.38, 99.22 Lr 0.0090\n",
            "Epoch[8](39/391): Loss 0.3844 Prec@1(1,5) 86.45, 99.61 Lr 0.0090\n",
            "Epoch[8](78/391): Loss 0.3854 Prec@1(1,5) 86.68, 99.53 Lr 0.0090\n",
            "Epoch[8](117/391): Loss 0.3990 Prec@1(1,5) 86.29, 99.51 Lr 0.0090\n",
            "Epoch[8](156/391): Loss 0.3976 Prec@1(1,5) 86.22, 99.49 Lr 0.0090\n",
            "Epoch[8](195/391): Loss 0.3961 Prec@1(1,5) 86.34, 99.50 Lr 0.0090\n",
            "Epoch[8](234/391): Loss 0.3996 Prec@1(1,5) 86.26, 99.48 Lr 0.0090\n",
            "Epoch[8](273/391): Loss 0.4014 Prec@1(1,5) 86.15, 99.46 Lr 0.0090\n",
            "Epoch[8](312/391): Loss 0.3991 Prec@1(1,5) 86.27, 99.46 Lr 0.0090\n",
            "Epoch[8](351/391): Loss 0.3988 Prec@1(1,5) 86.32, 99.49 Lr 0.0090\n",
            "Epoch[8](390/391): Loss 0.3984 Prec@1(1,5) 86.31, 99.51 Lr 0.0090\n",
            " * Acc@1 85.340 Acc@5 99.290\n",
            "=>Best accuracy 85.340\n",
            "learning_rate: 0.008345653031794291\n",
            "Epoch[9](0/391): Loss 0.4025 Prec@1(1,5) 85.94, 100.00 Lr 0.0083\n",
            "Epoch[9](39/391): Loss 0.3579 Prec@1(1,5) 87.70, 99.41 Lr 0.0083\n",
            "Epoch[9](78/391): Loss 0.3487 Prec@1(1,5) 88.18, 99.48 Lr 0.0083\n",
            "Epoch[9](117/391): Loss 0.3522 Prec@1(1,5) 88.08, 99.50 Lr 0.0083\n",
            "Epoch[9](156/391): Loss 0.3537 Prec@1(1,5) 88.00, 99.51 Lr 0.0083\n",
            "Epoch[9](195/391): Loss 0.3564 Prec@1(1,5) 87.89, 99.53 Lr 0.0083\n",
            "Epoch[9](234/391): Loss 0.3601 Prec@1(1,5) 87.79, 99.54 Lr 0.0083\n",
            "Epoch[9](273/391): Loss 0.3584 Prec@1(1,5) 87.81, 99.53 Lr 0.0083\n",
            "Epoch[9](312/391): Loss 0.3588 Prec@1(1,5) 87.79, 99.53 Lr 0.0083\n",
            "Epoch[9](351/391): Loss 0.3575 Prec@1(1,5) 87.83, 99.55 Lr 0.0083\n",
            "Epoch[9](390/391): Loss 0.3590 Prec@1(1,5) 87.78, 99.53 Lr 0.0083\n",
            " * Acc@1 85.010 Acc@5 99.200\n",
            "=>Best accuracy 85.340\n",
            "learning_rate: 0.0075\n",
            "Epoch[10](0/391): Loss 0.3382 Prec@1(1,5) 88.28, 100.00 Lr 0.0075\n",
            "Epoch[10](39/391): Loss 0.3186 Prec@1(1,5) 88.81, 99.80 Lr 0.0075\n",
            "Epoch[10](78/391): Loss 0.3156 Prec@1(1,5) 89.19, 99.73 Lr 0.0075\n",
            "Epoch[10](117/391): Loss 0.3206 Prec@1(1,5) 89.04, 99.70 Lr 0.0075\n",
            "Epoch[10](156/391): Loss 0.3200 Prec@1(1,5) 88.98, 99.71 Lr 0.0075\n",
            "Epoch[10](195/391): Loss 0.3207 Prec@1(1,5) 88.97, 99.67 Lr 0.0075\n",
            "Epoch[10](234/391): Loss 0.3200 Prec@1(1,5) 88.98, 99.67 Lr 0.0075\n",
            "Epoch[10](273/391): Loss 0.3211 Prec@1(1,5) 88.92, 99.65 Lr 0.0075\n",
            "Epoch[10](312/391): Loss 0.3213 Prec@1(1,5) 88.98, 99.65 Lr 0.0075\n",
            "Epoch[10](351/391): Loss 0.3214 Prec@1(1,5) 89.00, 99.65 Lr 0.0075\n",
            "Epoch[10](390/391): Loss 0.3227 Prec@1(1,5) 88.96, 99.65 Lr 0.0075\n",
            " * Acc@1 83.300 Acc@5 99.370\n",
            "=>Best accuracy 85.340\n",
            "learning_rate: 0.006545084971874737\n",
            "Epoch[11](0/391): Loss 0.2346 Prec@1(1,5) 89.84, 100.00 Lr 0.0065\n",
            "Epoch[11](39/391): Loss 0.2825 Prec@1(1,5) 90.25, 99.67 Lr 0.0065\n",
            "Epoch[11](78/391): Loss 0.2838 Prec@1(1,5) 90.38, 99.65 Lr 0.0065\n",
            "Epoch[11](117/391): Loss 0.2813 Prec@1(1,5) 90.53, 99.68 Lr 0.0065\n",
            "Epoch[11](156/391): Loss 0.2825 Prec@1(1,5) 90.62, 99.67 Lr 0.0065\n",
            "Epoch[11](195/391): Loss 0.2839 Prec@1(1,5) 90.48, 99.68 Lr 0.0065\n",
            "Epoch[11](234/391): Loss 0.2830 Prec@1(1,5) 90.41, 99.70 Lr 0.0065\n",
            "Epoch[11](273/391): Loss 0.2831 Prec@1(1,5) 90.39, 99.72 Lr 0.0065\n",
            "Epoch[11](312/391): Loss 0.2854 Prec@1(1,5) 90.28, 99.72 Lr 0.0065\n",
            "Epoch[11](351/391): Loss 0.2888 Prec@1(1,5) 90.17, 99.70 Lr 0.0065\n",
            "Epoch[11](390/391): Loss 0.2896 Prec@1(1,5) 90.15, 99.70 Lr 0.0065\n",
            " * Acc@1 86.980 Acc@5 99.560\n",
            "=>Best accuracy 86.980\n",
            "learning_rate: 0.005522642316338268\n",
            "Epoch[12](0/391): Loss 0.2108 Prec@1(1,5) 94.53, 100.00 Lr 0.0055\n",
            "Epoch[12](39/391): Loss 0.2467 Prec@1(1,5) 91.74, 99.75 Lr 0.0055\n",
            "Epoch[12](78/391): Loss 0.2473 Prec@1(1,5) 91.55, 99.74 Lr 0.0055\n",
            "Epoch[12](117/391): Loss 0.2482 Prec@1(1,5) 91.39, 99.79 Lr 0.0055\n",
            "Epoch[12](156/391): Loss 0.2466 Prec@1(1,5) 91.40, 99.81 Lr 0.0055\n",
            "Epoch[12](195/391): Loss 0.2486 Prec@1(1,5) 91.33, 99.80 Lr 0.0055\n",
            "Epoch[12](234/391): Loss 0.2509 Prec@1(1,5) 91.33, 99.78 Lr 0.0055\n",
            "Epoch[12](273/391): Loss 0.2530 Prec@1(1,5) 91.26, 99.77 Lr 0.0055\n",
            "Epoch[12](312/391): Loss 0.2534 Prec@1(1,5) 91.21, 99.78 Lr 0.0055\n",
            "Epoch[12](351/391): Loss 0.2530 Prec@1(1,5) 91.24, 99.77 Lr 0.0055\n",
            "Epoch[12](390/391): Loss 0.2559 Prec@1(1,5) 91.15, 99.77 Lr 0.0055\n",
            " * Acc@1 87.660 Acc@5 99.550\n",
            "=>Best accuracy 87.660\n",
            "learning_rate: 0.004477357683661734\n",
            "Epoch[13](0/391): Loss 0.3717 Prec@1(1,5) 89.06, 100.00 Lr 0.0045\n",
            "Epoch[13](39/391): Loss 0.2203 Prec@1(1,5) 92.60, 99.79 Lr 0.0045\n",
            "Epoch[13](78/391): Loss 0.2130 Prec@1(1,5) 92.72, 99.84 Lr 0.0045\n",
            "Epoch[13](117/391): Loss 0.2102 Prec@1(1,5) 92.66, 99.87 Lr 0.0045\n",
            "Epoch[13](156/391): Loss 0.2114 Prec@1(1,5) 92.64, 99.88 Lr 0.0045\n",
            "Epoch[13](195/391): Loss 0.2116 Prec@1(1,5) 92.57, 99.86 Lr 0.0045\n",
            "Epoch[13](234/391): Loss 0.2170 Prec@1(1,5) 92.48, 99.85 Lr 0.0045\n",
            "Epoch[13](273/391): Loss 0.2166 Prec@1(1,5) 92.54, 99.85 Lr 0.0045\n",
            "Epoch[13](312/391): Loss 0.2168 Prec@1(1,5) 92.53, 99.85 Lr 0.0045\n",
            "Epoch[13](351/391): Loss 0.2168 Prec@1(1,5) 92.55, 99.85 Lr 0.0045\n",
            "Epoch[13](390/391): Loss 0.2166 Prec@1(1,5) 92.58, 99.84 Lr 0.0045\n",
            " * Acc@1 88.410 Acc@5 99.600\n",
            "=>Best accuracy 88.410\n",
            "learning_rate: 0.003454915028125264\n",
            "Epoch[14](0/391): Loss 0.1748 Prec@1(1,5) 92.19, 100.00 Lr 0.0035\n",
            "Epoch[14](39/391): Loss 0.1932 Prec@1(1,5) 93.26, 99.92 Lr 0.0035\n",
            "Epoch[14](78/391): Loss 0.1863 Prec@1(1,5) 93.49, 99.90 Lr 0.0035\n",
            "Epoch[14](117/391): Loss 0.1839 Prec@1(1,5) 93.54, 99.90 Lr 0.0035\n",
            "Epoch[14](156/391): Loss 0.1850 Prec@1(1,5) 93.50, 99.89 Lr 0.0035\n",
            "Epoch[14](195/391): Loss 0.1873 Prec@1(1,5) 93.43, 99.89 Lr 0.0035\n",
            "Epoch[14](234/391): Loss 0.1895 Prec@1(1,5) 93.31, 99.89 Lr 0.0035\n",
            "Epoch[14](273/391): Loss 0.1898 Prec@1(1,5) 93.32, 99.89 Lr 0.0035\n",
            "Epoch[14](312/391): Loss 0.1907 Prec@1(1,5) 93.32, 99.89 Lr 0.0035\n",
            "Epoch[14](351/391): Loss 0.1909 Prec@1(1,5) 93.29, 99.88 Lr 0.0035\n",
            "Epoch[14](390/391): Loss 0.1914 Prec@1(1,5) 93.25, 99.88 Lr 0.0035\n",
            " * Acc@1 89.520 Acc@5 99.630\n",
            "=>Best accuracy 89.520\n",
            "learning_rate: 0.0025000000000000014\n",
            "Epoch[15](0/391): Loss 0.1434 Prec@1(1,5) 96.88, 100.00 Lr 0.0025\n",
            "Epoch[15](39/391): Loss 0.1493 Prec@1(1,5) 95.27, 99.94 Lr 0.0025\n",
            "Epoch[15](78/391): Loss 0.1543 Prec@1(1,5) 94.94, 99.90 Lr 0.0025\n",
            "Epoch[15](117/391): Loss 0.1508 Prec@1(1,5) 95.09, 99.91 Lr 0.0025\n",
            "Epoch[15](156/391): Loss 0.1499 Prec@1(1,5) 95.04, 99.93 Lr 0.0025\n",
            "Epoch[15](195/391): Loss 0.1499 Prec@1(1,5) 95.03, 99.93 Lr 0.0025\n",
            "Epoch[15](234/391): Loss 0.1517 Prec@1(1,5) 94.97, 99.93 Lr 0.0025\n",
            "Epoch[15](273/391): Loss 0.1518 Prec@1(1,5) 94.94, 99.94 Lr 0.0025\n",
            "Epoch[15](312/391): Loss 0.1523 Prec@1(1,5) 94.89, 99.94 Lr 0.0025\n",
            "Epoch[15](351/391): Loss 0.1523 Prec@1(1,5) 94.88, 99.94 Lr 0.0025\n",
            "Epoch[15](390/391): Loss 0.1538 Prec@1(1,5) 94.82, 99.94 Lr 0.0025\n",
            " * Acc@1 89.690 Acc@5 99.720\n",
            "=>Best accuracy 89.690\n",
            "learning_rate: 0.0016543469682057106\n",
            "Epoch[16](0/391): Loss 0.1433 Prec@1(1,5) 94.53, 100.00 Lr 0.0017\n",
            "Epoch[16](39/391): Loss 0.1329 Prec@1(1,5) 95.29, 99.92 Lr 0.0017\n",
            "Epoch[16](78/391): Loss 0.1286 Prec@1(1,5) 95.60, 99.94 Lr 0.0017\n",
            "Epoch[16](117/391): Loss 0.1281 Prec@1(1,5) 95.69, 99.96 Lr 0.0017\n",
            "Epoch[16](156/391): Loss 0.1298 Prec@1(1,5) 95.60, 99.95 Lr 0.0017\n",
            "Epoch[16](195/391): Loss 0.1290 Prec@1(1,5) 95.64, 99.94 Lr 0.0017\n",
            "Epoch[16](234/391): Loss 0.1288 Prec@1(1,5) 95.70, 99.95 Lr 0.0017\n",
            "Epoch[16](273/391): Loss 0.1291 Prec@1(1,5) 95.66, 99.95 Lr 0.0017\n",
            "Epoch[16](312/391): Loss 0.1313 Prec@1(1,5) 95.57, 99.95 Lr 0.0017\n",
            "Epoch[16](351/391): Loss 0.1324 Prec@1(1,5) 95.52, 99.95 Lr 0.0017\n",
            "Epoch[16](390/391): Loss 0.1325 Prec@1(1,5) 95.53, 99.95 Lr 0.0017\n",
            " * Acc@1 90.150 Acc@5 99.680\n",
            "=>Best accuracy 90.150\n",
            "learning_rate: 0.0009549150281252633\n",
            "Epoch[17](0/391): Loss 0.0663 Prec@1(1,5) 96.88, 100.00 Lr 0.0010\n",
            "Epoch[17](39/391): Loss 0.1156 Prec@1(1,5) 96.04, 99.96 Lr 0.0010\n",
            "Epoch[17](78/391): Loss 0.1178 Prec@1(1,5) 96.10, 99.97 Lr 0.0010\n",
            "Epoch[17](117/391): Loss 0.1139 Prec@1(1,5) 96.28, 99.97 Lr 0.0010\n",
            "Epoch[17](156/391): Loss 0.1142 Prec@1(1,5) 96.25, 99.97 Lr 0.0010\n",
            "Epoch[17](195/391): Loss 0.1171 Prec@1(1,5) 96.17, 99.95 Lr 0.0010\n",
            "Epoch[17](234/391): Loss 0.1151 Prec@1(1,5) 96.22, 99.96 Lr 0.0010\n",
            "Epoch[17](273/391): Loss 0.1126 Prec@1(1,5) 96.27, 99.96 Lr 0.0010\n",
            "Epoch[17](312/391): Loss 0.1125 Prec@1(1,5) 96.27, 99.97 Lr 0.0010\n",
            "Epoch[17](351/391): Loss 0.1124 Prec@1(1,5) 96.27, 99.97 Lr 0.0010\n",
            "Epoch[17](390/391): Loss 0.1129 Prec@1(1,5) 96.25, 99.97 Lr 0.0010\n",
            " * Acc@1 90.580 Acc@5 99.680\n",
            "=>Best accuracy 90.580\n",
            "learning_rate: 0.0004322727117869951\n",
            "Epoch[18](0/391): Loss 0.1395 Prec@1(1,5) 95.31, 100.00 Lr 0.0004\n",
            "Epoch[18](39/391): Loss 0.0928 Prec@1(1,5) 96.91, 99.98 Lr 0.0004\n",
            "Epoch[18](78/391): Loss 0.0998 Prec@1(1,5) 96.80, 99.95 Lr 0.0004\n",
            "Epoch[18](117/391): Loss 0.0996 Prec@1(1,5) 96.80, 99.95 Lr 0.0004\n",
            "Epoch[18](156/391): Loss 0.0984 Prec@1(1,5) 96.84, 99.96 Lr 0.0004\n",
            "Epoch[18](195/391): Loss 0.0977 Prec@1(1,5) 96.81, 99.97 Lr 0.0004\n",
            "Epoch[18](234/391): Loss 0.0977 Prec@1(1,5) 96.80, 99.97 Lr 0.0004\n",
            "Epoch[18](273/391): Loss 0.0983 Prec@1(1,5) 96.78, 99.97 Lr 0.0004\n",
            "Epoch[18](312/391): Loss 0.0974 Prec@1(1,5) 96.81, 99.96 Lr 0.0004\n",
            "Epoch[18](351/391): Loss 0.0977 Prec@1(1,5) 96.80, 99.96 Lr 0.0004\n",
            "Epoch[18](390/391): Loss 0.0980 Prec@1(1,5) 96.76, 99.96 Lr 0.0004\n",
            " * Acc@1 90.980 Acc@5 99.690\n",
            "=>Best accuracy 90.980\n",
            "learning_rate: 0.00010926199633097157\n",
            "Epoch[19](0/391): Loss 0.0364 Prec@1(1,5) 100.00, 100.00 Lr 0.0001\n",
            "Epoch[19](39/391): Loss 0.0925 Prec@1(1,5) 96.91, 99.96 Lr 0.0001\n",
            "Epoch[19](78/391): Loss 0.0920 Prec@1(1,5) 96.87, 99.95 Lr 0.0001\n",
            "Epoch[19](117/391): Loss 0.0917 Prec@1(1,5) 96.93, 99.95 Lr 0.0001\n",
            "Epoch[19](156/391): Loss 0.0914 Prec@1(1,5) 96.90, 99.96 Lr 0.0001\n",
            "Epoch[19](195/391): Loss 0.0925 Prec@1(1,5) 96.91, 99.96 Lr 0.0001\n",
            "Epoch[19](234/391): Loss 0.0923 Prec@1(1,5) 96.93, 99.96 Lr 0.0001\n",
            "Epoch[19](273/391): Loss 0.0940 Prec@1(1,5) 96.87, 99.95 Lr 0.0001\n",
            "Epoch[19](312/391): Loss 0.0938 Prec@1(1,5) 96.86, 99.95 Lr 0.0001\n",
            "Epoch[19](351/391): Loss 0.0923 Prec@1(1,5) 96.95, 99.96 Lr 0.0001\n",
            "Epoch[19](390/391): Loss 0.0915 Prec@1(1,5) 97.01, 99.96 Lr 0.0001\n",
            " * Acc@1 90.940 Acc@5 99.730\n",
            "=>Best accuracy 90.980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 3: Prune the baseline model**"
      ],
      "metadata": {
        "id": "6pFryMvGXX9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compress_rate = [0.25]*13 # prune 25% of all layers\n",
        "model_prune = vgg_16_bn(compress_rate=compress_rate).cuda()\n",
        "print(model_prune)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxxynwaVXbp5",
        "outputId": "060540c1-0aa7-41c7-86f1-fc1a7176b020"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm0): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv3): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu3): ReLU(inplace=True)\n",
            "    (conv4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu4): ReLU(inplace=True)\n",
            "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv6): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu6): ReLU(inplace=True)\n",
            "    (conv7): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu7): ReLU(inplace=True)\n",
            "    (conv8): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu8): ReLU(inplace=True)\n",
            "    (pool9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv10): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu10): ReLU(inplace=True)\n",
            "    (conv11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm11): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu11): ReLU(inplace=True)\n",
            "    (conv12): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm12): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu12): ReLU(inplace=True)\n",
            "    (pool13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv14): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm14): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu14): ReLU(inplace=True)\n",
            "    (conv15): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm15): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu15): ReLU(inplace=True)\n",
            "    (conv16): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (norm16): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu16): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (linear1): Linear(in_features=384, out_features=512, bias=True)\n",
            "    (norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (linear2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you have the architecture of the prune-model. *Validate the difference of the number of the filter in each layer between the prune-model and the baseline model*.\n",
        "\n",
        "Your task is to select which filters from the baseline model to keep (or which ones to remove). You can do this by iterating through layers of the model. In each layer, calculate the similarity matrix and decide the importance of each filter. Next, copy the parameter of the filters to be kept in the baseline model to the prune-model.\n",
        "\n",
        "You may found help [here](https://github.com/pvtien96/CORING/blob/ec9adfe8c2a1b577d5cd6b6d88adc548d34d71f0/main/main.py#L202)\n",
        "\n",
        "Finally, fine-tune the prune-model to see the accuracy."
      ],
      "metadata": {
        "id": "qZJvFh7DZPtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 4: Analysis & Conclusion**\n"
      ],
      "metadata": {
        "id": "Mj3E7RhifLd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some questions for you to consider while working on this project:\n",
        "1. **What is the relation between compression rate, reduced complexity/parameters, and accuracy?**\n",
        "   - How does increasing the compression rate affect the model's accuracy?\n",
        "   - Can you explain the trade-off between model complexity (number of parameters) and accuracy?\n",
        "\n",
        "2. **How do you decide the importance of filters?**\n",
        "   - What criteria can be used to determine the importance of filters in a convolutional neural network?\n",
        "   - How do similarity-based filter pruning techniques identify redundant or less important filters?\n",
        "   - Can you explain the concept of filter importance in the context of model efficiency and effectiveness?\n",
        "\n",
        "3. **What are the implications of pruning on model performance and inference speed?**\n",
        "   - How does pruning affect the inference speed of a model?\n",
        "   - Can you discuss the impact of pruning on model accuracy during inference?\n",
        "   - What strategies can be employed to mitigate any potential loss of accuracy after pruning?\n",
        "\n",
        "4. **How does fine-tuning help improve the performance of pruned models?**\n",
        "   - What is the purpose of fine-tuning a pruned model?\n",
        "   - How does fine-tuning help the model adapt to the changes introduced by pruning?\n",
        "   - Can you explain any challenges or considerations when fine-tuning pruned models?\n",
        "\n",
        "5. **What are some alternative pruning techniques, and how do they compare to similarity-based pruning?**\n",
        "   - Can you describe magnitude-based pruning and its advantages/disadvantages compared to similarity-based pruning?\n",
        "   - What is sensitivity-based pruning, and how does it differ from similarity-based pruning?\n",
        "   - Are there any hybrid approaches that combine multiple pruning techniques for better results?"
      ],
      "metadata": {
        "id": "zj54KZqqfgME"
      }
    }
  ]
}